---
title: "データのセキュリティと暗号化"
date: 2024-05-07T23:29:28+09:00
tags: [Infrastructure]
draft: false
---

# データのセキュリティと暗号化
データの暗号化関係は (参考資料1) 配下に資料有り。以下を KMS の暗号化対象として設定可能 (参考資料2)。

- コントロールプレーン … ノートブックやクエリ
- ワークスペース … ワークスペースのルートS3バケット、クラスターのEBS (注意点有り)
- S3バケット … spark で read, write する際のデータ

# S3バケット内全てを暗号化する
ワークスペース暗号化を行っても全てのファイルは暗号化されない。  
(実機にてマネージドテーブルが暗号化されていないことを確認)

全ファイルの暗号化はバケットのデフォルト暗号化へ KMS を指定してやることで可能。その場合は Databricks のアカウントコンソールの「ストレージ設定」に登録してある IAM ロールに対して、作成した KMS の鍵を使用する権限を付与する (参考資料4)。

# やってみる
- AWS KMS で CMK を作成
  - タイプ: 対称キー
  - 使用法: 暗号化および復号化
  - キーマテリアルオリジン: KMS
  - リージョン: 単一リージョンキー
  - エイリアス: (分かりやすい名前)
  - キー管理者: (自身の IAM User)
  - キーユーザー: (なし)
  - ポリシー: Databricks アカウント管理画面から「暗号化キー設定」のキー追加を開き、表示されるポリシーをコピペ。プレースホルダー箇所 (`<cross-account-iam-role-arn>`) を資格情報として登録している IAM ロールのARNへ置換 (Databricks からのキー使用を許可)
- AWS IAM で Workspace S3 バケットアクセス用 IAM ロールへ権限追加
  - 作成した KMS CMK に対して以下操作を行うする権限を追加 (参考資料4)  
    ```json
    {
      "Action": [
        "kms:Decrypt",
        "kms:Encrypt",
        "kms:GenerateDataKey*"
      ],
      "Resource": [
        "arn:aws:kms:<KMS-KEY>"
      ],
      "Effect": "Allow"
    }
    ```
- Databricks アカウントコンソール
  - 暗号化キー設定からキー追加
  - ワークスペース作成 (作成する際、資格情報の設定で「高度な設定」を押し、暗号化キーを指定)
- Databricks ワークスペース
  - ワークスペース S3 バケットのデフォルト暗号化の設定を KMS へ変更
  - クラスター作成時の Spark 構成の設定値を追加 (参考資料3)
    ```
    spark.hadoop.fs.s3a.server-side-encryption.key (CMK-ARN)
    spark.hadoop.fs.s3a.server-side-encryption-algorithm SSE-KMS
    ```

# 参考資料
1. [データのセキュリティと暗号化](https://docs.databricks.com/ja/security/keys/index.html)  
2. [暗号化用のカスタマーマネージドキー](https://docs.databricks.com/ja/security/keys/customer-managed-keys.html)
3. [KMS を使用した S3 の暗号化の設定](https://docs.databricks.com/ja/security/keys/kms-s3.html)
4. [Unity Catalog メタストアを作成する](https://docs.databricks.com/ja/data-governance/unity-catalog/create-metastore.html)