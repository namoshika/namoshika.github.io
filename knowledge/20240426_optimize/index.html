<!doctype html><html lang=ja-jp><head><meta charset=utf-8><meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="Spark でデータ処理を書いていて生じたクエリのパフォーマンス問題へ対処する過程で分かった事、見つけた Databricks の便利な機能を記載する。 効率的な処理の基本 Spark"><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><meta name=generator content="Hugo 0.133.1"><title>Spark でパフォーマンスに問題のあるクエリを最適化する | Memo.Namo</title>
<meta name=robots content="noindex, nofollow"><link rel=stylesheet href=/style/main.css></head><body><div class=flexbox><div><header id=site-header class=toplevel-container><h1><a href=/>Memo.Namo</a></h1><nav><ul class=horizontal-menu><li class=horizontal-menu-item><a href=/about/>About</a></li><li class=horizontal-menu-item><a href=/knowledge/>Knowledge</a></li></ul></nav></header><main id=site-main class=toplevel-container><article class="content-container content-grid"><header class=content-grid-header><div><a class=nav-category href=/knowledge/databricks/>Databricks</a><h1 class=content-grid-title>Spark でパフォーマンスに問題のあるクエリを最適化する</h1></div><p class=content-grid-desc><span>公開日: 2024-08-01</span>
<span>更新日: 2024-09-03</span></p></header><aside class=content-grid-side><div class=nav-sticky><h2>目次</h2><nav id=TableOfContents><ul><li><a href=#効率的な処理の基本>効率的な処理の基本</a></li><li><a href=#分析方法1-実行計画を読む>分析方法1: 実行計画を読む</a></li><li><a href=#分析方法2-クエリープロファイルを読む>分析方法2: クエリープロファイルを読む</a></li><li><a href=#クエリを最適化する>クエリを最適化する</a></li><li><a href=#検証ノートブック>検証ノートブック</a><ul><li><a href=#1-view-の影響>1. View の影響</a></li><li><a href=#2-絞り込み項目による影響>2. 絞り込み項目による影響</a></li><li><a href=#3-絞り込み方法による影響>3. 絞り込み方法による影響</a></li></ul></li><li><a href=#参考資料>参考資料</a></li></ul></nav><nav class=nav-tag><h2>タグ</h2><ul class=tag-container><li class="tag-item tag-item-inactive"><a href=/tags/auth/>Auth</a></li><li class="tag-item tag-item-inactive"><a href=/tags/businessman/>BusinessMan</a></li><li class="tag-item tag-item-inactive"><a href=/tags/database/>Database</a></li><li class="tag-item tag-item-active"><a href=/tags/dataengineering/>DataEngineering</a></li><li class="tag-item tag-item-inactive"><a href=/tags/datavisualization/>DataVisualization</a></li><li class="tag-item tag-item-inactive"><a href=/tags/devops/>DevOps</a></li><li class="tag-item tag-item-inactive"><a href=/tags/iac/>IaC</a></li><li class="tag-item tag-item-inactive"><a href=/tags/infrastructure/>Infrastructure</a></li></ul></nav></div></aside><section class="md-content content-grid-main"><p>Spark でデータ処理を書いていて生じたクエリのパフォーマンス問題へ対処する過程で分かった事、見つけた Databricks の便利な機能を記載する。</p><h1 id=効率的な処理の基本>効率的な処理の基本</h1><p>Spark では巨大なデータセットを複数台のマシンで並列分散処理する事ができるが、効率的に行いたい場合には以下を心掛ける必要が有る。</p><ul><li>必要なデータのみをロードさせる</li><li>処理中のデータのシャッフルを避ける</li></ul><p>不要なデータを処理させないように作る事が基本となる。また、処理の中にはレコード同士を独立して処理できるものも有れば、レコード間で影響し合う処理も有る。 Spark では後者の処理を行う際にマシン間で処理中のデータをデータに応じて再配置する「シャッフル」が発生する。このシャッフルは非常に高コストな処理とされ、これを避ける事も効果が有る。</p><h1 id=分析方法1-実行計画を読む>分析方法1: 実行計画を読む</h1><p>パフォーマンスに問題が有る場合、Spark がクエリをどのように実行しようとしているか (実行計画) を知る事は対処を考える際の取っ掛かりとなる。これはお馴染みの EXPLAIN 文で取得可能。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=c1>-- EXPLAIN COST {Query}.
</span></span></span><span class=line><span class=cl><span class=c1>-- 論理プランと統計情報を見るために COST オプションを付与.
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>EXPLAIN</span><span class=w> </span><span class=n>COST</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>SELECT</span><span class=w> </span><span class=n>A</span><span class=p>.</span><span class=o>*</span><span class=w> </span><span class=k>FROM</span><span class=w> </span><span class=n>samples</span><span class=p>.</span><span class=n>tpch</span><span class=p>.</span><span class=n>lineitem</span><span class=w> </span><span class=n>A</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>INNER</span><span class=w> </span><span class=k>JOIN</span><span class=w> </span><span class=n>samples</span><span class=p>.</span><span class=n>tpch</span><span class=p>.</span><span class=n>orders</span><span class=w> </span><span class=n>B</span><span class=w> </span><span class=k>ON</span><span class=w> </span><span class=n>A</span><span class=p>.</span><span class=n>l_orderkey</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>B</span><span class=p>.</span><span class=n>o_orderkey</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>WHERE</span><span class=w> </span><span class=n>B</span><span class=p>.</span><span class=n>o_orderkey</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=mi>16048416</span><span class=w>
</span></span></span></code></pre></div><p>例えば上を実行すると以下のような出力が得られる。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-gdscript3 data-lang=gdscript3><span class=line><span class=cl><span class=n>plan</span>
</span></span><span class=line><span class=cl><span class=s2>&#34;== Optimized Logical Plan ==</span>
</span></span><span class=line><span class=cl><span class=n>Project</span> <span class=p>[</span><span class=n>l_orderkey</span><span class=c1>#9623L, l_partkey#9624L, l_suppkey#9625L, l_linenumber#9626, l_quantity#9627, l_extendedprice#9628, l_discount#9629, l_tax#9630, l_returnflag#9631, l_linestatus#9632, l_shipdate#9633, l_commitdate#9634, l_receiptdate#9635, l_shipinstruct#9636, l_shipmode#9637, l_comment#9638], Statistics(sizeInBytes=1669.0 TiB, ColumnStat: N/A)</span>
</span></span><span class=line><span class=cl><span class=o>+-</span> <span class=n>Join</span> <span class=n>Inner</span><span class=p>,</span> <span class=p>(</span><span class=n>l_orderkey</span><span class=c1>#9623L = o_orderkey#9639L), Statistics(sizeInBytes=1743.2 TiB, ColumnStat: N/A)</span>
</span></span><span class=line><span class=cl>   <span class=p>:</span><span class=o>-</span> <span class=n>Filter</span> <span class=p>(</span><span class=n>isnotnull</span><span class=p>(</span><span class=n>l_orderkey</span><span class=c1>#9623L) AND (l_orderkey#9623L = 16048416)), Statistics(sizeInBytes=735.4 MiB, ColumnStat: N/A)</span>
</span></span><span class=line><span class=cl>   <span class=p>:</span>  <span class=o>+-</span> <span class=n>Relation</span> <span class=n>samples</span><span class=o>.</span><span class=n>tpch</span><span class=o>.</span><span class=n>lineitem</span><span class=p>[</span><span class=n>l_orderkey</span><span class=c1>#9623L,l_partkey#9624L,l_suppkey#9625L,l_linenumber#9626,l_quantity#9627,l_extendedprice#9628,l_discount#9629,l_tax#9630,l_returnflag#9631,l_linestatus#9632,l_shipdate#9633,l_commitdate#9634,l_receiptdate#9635,l_shipinstruct#9636,l_shipmode#9637,l_comment#9638] parquet, Statistics(sizeInBytes=735.4 MiB, ColumnStat: N/A)</span>
</span></span><span class=line><span class=cl>   <span class=o>+-</span> <span class=n>Project</span> <span class=p>[</span><span class=n>o_orderkey</span><span class=c1>#9639L], Statistics(sizeInBytes=36.3 MiB, ColumnStat: N/A)</span>
</span></span><span class=line><span class=cl>      <span class=o>+-</span> <span class=n>Filter</span> <span class=p>(</span><span class=n>isnotnull</span><span class=p>(</span><span class=n>o_orderkey</span><span class=c1>#9639L) AND (o_orderkey#9639L = 16048416)), Statistics(sizeInBytes=272.4 MiB, ColumnStat: N/A)</span>
</span></span><span class=line><span class=cl>         <span class=o>+-</span> <span class=n>Relation</span> <span class=n>samples</span><span class=o>.</span><span class=n>tpch</span><span class=o>.</span><span class=n>orders</span><span class=p>[</span><span class=n>o_orderkey</span><span class=c1>#9639L,o_custkey#9640L,o_orderstatus#9641,o_totalprice#9642,o_orderdate#9643,o_orderpriority#9644,o_clerk#9645,o_shippriority#9646,o_comment#9647] parquet, Statistics(sizeInBytes=272.4 MiB, ColumnStat: N/A)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=o>==</span> <span class=n>Physical</span> <span class=n>Plan</span> <span class=o>==</span>
</span></span><span class=line><span class=cl><span class=n>AdaptiveSparkPlan</span> <span class=n>isFinalPlan</span><span class=o>=</span><span class=bp>false</span>
</span></span><span class=line><span class=cl><span class=o>+-</span> <span class=n>ColumnarToRow</span>
</span></span><span class=line><span class=cl>   <span class=o>+-</span> <span class=n>PhotonResultStage</span>
</span></span><span class=line><span class=cl>      <span class=o>+-</span> <span class=n>PhotonProject</span> <span class=p>[</span><span class=n>l_orderkey</span><span class=c1>#9623L, l_partkey#9624L, l_suppkey#9625L, l_linenumber#9626, l_quantity#9627, l_extendedprice#9628, l_discount#9629, l_tax#9630, l_returnflag#9631, l_linestatus#9632, l_shipdate#9633, l_commitdate#9634, l_receiptdate#9635, l_shipinstruct#9636, l_shipmode#9637, l_comment#9638]</span>
</span></span><span class=line><span class=cl>         <span class=o>+-</span> <span class=n>PhotonShuffledHashJoin</span> <span class=p>[</span><span class=n>l_orderkey</span><span class=c1>#9623L], [o_orderkey#9639L], Inner, BuildRight</span>
</span></span><span class=line><span class=cl>            <span class=p>:</span><span class=o>-</span> <span class=n>PhotonShuffleExchangeSource</span>
</span></span><span class=line><span class=cl>            <span class=p>:</span>  <span class=o>+-</span> <span class=n>PhotonShuffleMapStage</span>
</span></span><span class=line><span class=cl>            <span class=p>:</span>     <span class=o>+-</span> <span class=n>PhotonShuffleExchangeSink</span> <span class=n>hashpartitioning</span><span class=p>(</span><span class=n>l_orderkey</span><span class=c1>#9623L, 16)</span>
</span></span><span class=line><span class=cl>            <span class=p>:</span>        <span class=o>+-</span> <span class=n>PhotonScan</span> <span class=n>parquet</span> <span class=n>samples</span><span class=o>.</span><span class=n>tpch</span><span class=o>.</span><span class=n>lineitem</span><span class=p>[</span><span class=n>l_orderkey</span><span class=c1>#9623L,l_partkey#9624L,l_suppkey#9625L,l_linenumber#9626,l_quantity#9627,l_extendedprice#9628,l_discount#9629,l_tax#9630,l_returnflag#9631,l_linestatus#9632,l_shipdate#9633,l_commitdate#9634,l_receiptdate#9635,l_shipinstruct#9636,l_shipmode#9637,l_comment#9638] DataFilters: [isnotnull(l_orderkey#9623L), (l_orderkey#9623L = 16048416)], DictionaryFilters: [(l_orderkey#9623L = 16048416)], Format: parquet, Location: PreparedDeltaFileIndex(1 paths)[dbfs:/databricks-datasets/tpch/delta-001/lineitem], PartitionFilters: [], ReadSchema: struct&lt;l_orderkey:bigint,l_partkey:bigint,l_suppkey:bigint,l_linenumber:int,l_quantity:decimal(18..., RequiredDataFilters: [isnotnull(l_orderkey#9623L), (l_orderkey#9623L = 16048416)]</span>
</span></span><span class=line><span class=cl>            <span class=o>+-</span> <span class=n>PhotonShuffleExchangeSource</span>
</span></span><span class=line><span class=cl>               <span class=o>+-</span> <span class=n>PhotonShuffleMapStage</span>
</span></span><span class=line><span class=cl>                  <span class=o>+-</span> <span class=n>PhotonShuffleExchangeSink</span> <span class=n>hashpartitioning</span><span class=p>(</span><span class=n>o_orderkey</span><span class=c1>#9639L, 16)</span>
</span></span><span class=line><span class=cl>                     <span class=o>+-</span> <span class=n>PhotonScan</span> <span class=n>parquet</span> <span class=n>samples</span><span class=o>.</span><span class=n>tpch</span><span class=o>.</span><span class=n>orders</span><span class=p>[</span><span class=n>o_orderkey</span><span class=c1>#9639L] DataFilters: [isnotnull(o_orderkey#9639L), (o_orderkey#9639L = 16048416)], DictionaryFilters: [(o_orderkey#9639L = 16048416)], Format: parquet, Location: PreparedDeltaFileIndex(1 paths)[dbfs:/databricks-datasets/tpch/delta-001/orders], PartitionFilters: [], ReadSchema: struct&lt;o_orderkey:bigint&gt;, RequiredDataFilters: [isnotnull(o_orderkey#9639L), (o_orderkey#9639L = 16048416)]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=s2>&#34;</span>
</span></span></code></pre></div><p>出力結果はクエリをツリー構造で表現したものとなる。Spark は SQL や DataFrame を以下の段階を経て RDD へ変換し実行する (参考資料1)。 EXPLAIN は Spark がクエリをどのように実行するのかを知る際に使える。</p><ol><li>構文解析された論理プラン (Parsed Logical Plan)</li><li>意味解析された論理プラン (Analyzed Logical Plan)</li><li>最適化された論理プラン (Optimized Logical Plan)</li><li>物理プラン (Physical Plan)</li></ol><p>このような実行計画において以下のノードには注意が必要となる。</p><ul><li><strong>Statistics(sizeInBytes=1743.2 TiB</strong>:<br>論理プランにノードが扱うデータセットの予想サイズとして出力される。小さい程に不要なデータロードの回避が期待できる</li><li><strong>Join LeftSemi</strong>:<br>where 句の中でサブクエリによる絞込みをすると論理プランに現れる。記事執筆時の検証では両者に物理プランの差は無いが、 Join Inner (内部結合) に書き換える方が良いとする有識者も居る。</li><li><strong>PhotonShuffledHashJoin</strong>:<br>結合を行うと物理プランに現れてシャッフルを発生させる。結合の左右いずれかのデータセットサイズを小さく抑えられる場合 (閾値: <code>spark.sql.autoBroadcastJoinThreshold</code>. 既定 10MB. 参考資料2) 、Spark へ上手く伝達できるとより効率的な PhotonBroadcastHashJoin に取って代わらせることが出来る</li></ul><h1 id=分析方法2-クエリープロファイルを読む>分析方法2: クエリープロファイルを読む</h1><p>Databricks では SQL Warehouse で実行したクエリからはグラフィカルなUIで情報を得る機能が有る。ノートブック上で分析対象のクエリを実行した場合には以下の箇所をクリックする事で開くことが可能。</p><p>得られる情報のうち、「プルーニング済みバイト数」や「プルーニングされたファイル」はテーブル参照時に読み込みをスキップできたサイズやファイル数となる。</p><p><img src=image/queryprofile_001.png alt=queryprofile_001.png></p><p>また、「クエリープロファイルを表示」からは EXPLAIN と近い情報を得る事ができる。</p><p><img src=image/queryprofile_002.png alt=queryprofile_002.png></p><p>クエリープロファイルにおいても EXPLAIN と同様の箇所に注意を向けることが可能。さらにノードをクリックすると右側が詳細に切り替わり、細かい情報を得ることができる。結合時のジョイン方法が確認可能である他、実行後に得られる情報 (処理時間、出力行数、最大消費メモリ量 etc) も読めるため、要改善箇所の特定ではより扱いやすい。</p><ul><li><strong>Scan:</strong><br>テーブル読込み箇所に現れる。詳細画面のうち、「Size of files pruned」項目が読込みスキップできたデータセットサイズを表し、スキップできるほど望ましい</li><li><strong>～ Join:</strong><br>テーブル結合箇所に現れる。詳細画面のうち、「Join algorithm」項目がジョイン方法を表し、EXPLAIN の節で紹介した事柄と同様の事が確認可能</li></ul><h1 id=クエリを最適化する>クエリを最適化する</h1><p>以上の方法で分析しクエリを修正した結果、効率的なクエリの実行計画を生成させるには以下の事が有効だった。基本的な事を積み重ねていくことになる。</p><ol><li>複雑なクエリを実行するテーブルには Delta Lake を使う</li><li>Delta Lake へは列単位の統計情報を付与する</li><li>Delta Lake へデータスキップ項目を設定する</li><li>パーティションよりもリキッドクラスター (場合により Z-order も) を使う</li><li>テーブル参照は View を介さず直接参照する</li><li>絞込み条件に動的生成値を使わない</li><li>where 句のサブクエリ条件のうち、内部結合に置換可能なものは置換する</li></ol><p>可能な限りデータセットは Databricks 側へ取り込んだ方が良い (既定で使用される Delta Lake はパフォーマンスをはじめメリットが多く有る)。また、以下のSQLでテーブルの統計情報は最新化できる。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=c1>-- (下のサンプルテーブルは読み取り専用のため実行するとエラーが出る. 読書き可能テーブルで行うこと)
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>ANALYZE</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=n>samples</span><span class=p>.</span><span class=n>tpch</span><span class=p>.</span><span class=n>lineitem</span><span class=w> </span><span class=n>COMPUTE</span><span class=w> </span><span class=k>STATISTICS</span><span class=w> </span><span class=k>FOR</span><span class=w> </span><span class=k>ALL</span><span class=w> </span><span class=n>COLUMNS</span><span class=w>
</span></span></span></code></pre></div><p>Delta Lake で先頭32列より後ろの列をフィルタ条件に使う場合にはデータスキップ項目を手動設定する。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=c1>-- テーブル定義時に行う
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>CREATE</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=n>sample_tbl</span><span class=w> </span><span class=p>(...)</span><span class=w> </span><span class=n>TBLPROPERTIES</span><span class=w> </span><span class=p>(</span><span class=s1>&#39;delta.dataSkippingStatsColumns&#39;</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s1>&#39;col_a,`日本語も可能`&#39;</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>-- テーブル定義後に行う
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>ALTER</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=n>sample_tbl</span><span class=w> </span><span class=k>SET</span><span class=w> </span><span class=n>TBLPROPERTIES</span><span class=w> </span><span class=p>(</span><span class=s1>&#39;delta.dataSkippingStatsColumns&#39;</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s1>&#39;col_a,`日本語も可能`&#39;</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>-- alter で後から設定した場合には統計情報の再計算が必要
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>ANALYZE</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=n>sample_tbl</span><span class=w> </span><span class=n>COMPUTE</span><span class=w> </span><span class=n>DELTA</span><span class=w> </span><span class=k>STATISTICS</span><span class=w>
</span></span></span></code></pre></div><p>絞込み条件で組み立てる値はテーブル列として事前に値を生成しておくことがお勧め。日付 (yyyy, mm, dd) を繋げる (yyyymmdd) などが考えられる。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=c1>-- Before
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>select</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=k>from</span><span class=w> </span><span class=n>samples</span><span class=p>.</span><span class=n>tpch</span><span class=p>.</span><span class=n>lineitem</span><span class=w> </span><span class=k>where</span><span class=w> </span><span class=n>lpad</span><span class=p>(</span><span class=n>l_orderkey</span><span class=p>,</span><span class=w> </span><span class=mi>10</span><span class=p>,</span><span class=w> </span><span class=s2>&#34;0&#34;</span><span class=p>)</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s2>&#34;0016048416&#34;</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>-- After (Prep)
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>create</span><span class=w> </span><span class=k>or</span><span class=w> </span><span class=k>replace</span><span class=w> </span><span class=k>table</span><span class=w> </span><span class=n>lineitem_2</span><span class=w> </span><span class=k>as</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>select</span><span class=w> </span><span class=n>lpad</span><span class=p>(</span><span class=n>l_orderkey</span><span class=p>,</span><span class=w> </span><span class=mi>10</span><span class=p>,</span><span class=w> </span><span class=s2>&#34;0&#34;</span><span class=p>)</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=n>orderkey</span><span class=p>,</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=k>from</span><span class=w> </span><span class=n>samples</span><span class=p>.</span><span class=n>tpch</span><span class=p>.</span><span class=n>lineitem</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>-- After (Query)
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>select</span><span class=w> </span><span class=o>*</span><span class=w> </span><span class=k>from</span><span class=w> </span><span class=n>lineitem_2</span><span class=w> </span><span class=k>where</span><span class=w> </span><span class=n>orderkey</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s2>&#34;0016048416&#34;</span><span class=p>;</span><span class=w>
</span></span></span></code></pre></div><p>絞込み条件のうち、内部結合で表現可能なものは実行計画を比較した上で最良の方法を選択すると良い。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=c1>-- Before
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>select</span><span class=w> </span><span class=n>A</span><span class=p>.</span><span class=o>*</span><span class=w> </span><span class=k>from</span><span class=w> </span><span class=n>samples</span><span class=p>.</span><span class=n>tpch</span><span class=p>.</span><span class=n>lineitem</span><span class=w> </span><span class=n>A</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>where</span><span class=w> </span><span class=n>A</span><span class=p>.</span><span class=n>l_orderkey</span><span class=w> </span><span class=k>in</span><span class=w> </span><span class=p>(</span><span class=k>select</span><span class=w> </span><span class=n>B</span><span class=p>.</span><span class=n>o_orderkey</span><span class=w> </span><span class=k>from</span><span class=w> </span><span class=n>samples</span><span class=p>.</span><span class=n>tpch</span><span class=p>.</span><span class=n>orders</span><span class=w> </span><span class=n>B</span><span class=w> </span><span class=k>where</span><span class=w> </span><span class=n>B</span><span class=p>.</span><span class=n>o_orderkey</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=mi>16048416</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>-- After
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>select</span><span class=w> </span><span class=n>A</span><span class=p>.</span><span class=o>*</span><span class=w> </span><span class=k>from</span><span class=w> </span><span class=n>samples</span><span class=p>.</span><span class=n>tpch</span><span class=p>.</span><span class=n>lineitem</span><span class=w> </span><span class=n>A</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>inner</span><span class=w> </span><span class=k>join</span><span class=w> </span><span class=n>samples</span><span class=p>.</span><span class=n>tpch</span><span class=p>.</span><span class=n>orders</span><span class=w> </span><span class=n>B</span><span class=w> </span><span class=k>on</span><span class=w> </span><span class=n>A</span><span class=p>.</span><span class=n>l_orderkey</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>B</span><span class=p>.</span><span class=n>o_orderkey</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>where</span><span class=w> </span><span class=n>B</span><span class=p>.</span><span class=n>o_orderkey</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=mi>16048416</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>;</span><span class=w>
</span></span></span></code></pre></div><h1 id=検証ノートブック>検証ノートブック</h1><p>以下のリポジトリで以下の観点で検証を行った。ナイーブな気が&mldr; 実際の場面では Adaptive Query Execution である程度改善されるのではとも思っている。</p><p>ノートブック: <a href=https://github.com/namoshika/hello-databricks/blob/main/workspace/query_profiling_01.sql>GitHub</a><br>実行環境: SQL Warehouse (DBSQL v2024.35)</p><h2 id=1-view-の影響>1. View の影響</h2><p>View から列の統計情報を取得できないのか (実行計画に ColumnStat: N/A が出る)、物理テーブルのみで構成されていたクエリに View が入り込むとブロードキャスト結合されていた箇所がシャッフルハッシュジョインになる。</p><table><thead><tr><th>Case</th><th>Table</th><th>Time</th><th>Read / Pruned file</th><th>Physical plan</th></tr></thead><tbody><tr><td>table - table</td><td>output_case1_1</td><td>4 sec</td><td>120.36 MB / 13.81 GB</td><td>PhotonBroadcastHashJoin</td></tr><tr><td>table - view</td><td>output_case1_2</td><td>6 sec</td><td>10.45 GB / 4.33 GB</td><td>PhotonShuffledHashJoin</td></tr><tr><td>view - view</td><td>output_case1_3</td><td>5 sec</td><td>10.45 GB / 4.33 GB</td><td>PhotonShuffledHashJoin</td></tr></tbody></table><h2 id=2-絞り込み項目による影響>2. 絞り込み項目による影響</h2><p>絞り込み条件に動的生成列を使うと不要データのロードがスキップされなくなる。ジョイン戦略も変わり、不要なシャッフルを誘発する (列に統計情報が無いために最適な実行計画が作成されない)</p><table><thead><tr><th>絞り込み</th><th>Table</th><th>Time</th><th>Read / Pruned file</th><th>Physical plan</th></tr></thead><tbody><tr><td>静的生成</td><td>output_case2_1</td><td>14 sec</td><td>120.21 MB / 13.81 GB</td><td>PhotonBroadcastHashJoin</td></tr><tr><td>動的生成</td><td>output_case2_2</td><td>17 sec</td><td>10.89 GB / -</td><td>PhotonShuffledHashJoin</td></tr></tbody></table><h2 id=3-絞り込み方法による影響>3. 絞り込み方法による影響</h2><p>サブクエリによる絞り込みを行うと Left Semi Join が発生する (Databricks 社の人曰く、遅くなる)。物理実行計画では通常の結合に変換されている。</p><table><thead><tr><th>絞り込み</th><th>Table</th><th>Time</th><th>Read / Pruned file</th><th>Physical plan</th></tr></thead><tbody><tr><td>サブクエリ</td><td>output_case3_1</td><td>3 sec</td><td>120.36 MB / 13.81 GB</td><td>PhotonBroadcastHashJoin</td></tr><tr><td>内部結合</td><td>output_case3_2</td><td>3 sec</td><td>120.36 MB / 13.81 GB</td><td>PhotonShuffledHashJoin</td></tr></tbody></table><h1 id=参考資料>参考資料</h1><ol><li>Deep Dive into Spark SQL&rsquo;s Catalyst Optimizer<br><a href=https://www.databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html>https://www.databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html</a></li><li>Performance Tuning<br><a href=https://spark.apache.org/docs/latest/sql-performance-tuning.html>https://spark.apache.org/docs/latest/sql-performance-tuning.html</a></li><li>Adaptive Query Execution: Speeding Up Spark SQL at Runtime<br><a href=https://www.databricks.com/blog/2020/05/29/adaptive-query-execution-speeding-up-spark-sql-at-runtime.html>https://www.databricks.com/blog/2020/05/29/adaptive-query-execution-speeding-up-spark-sql-at-runtime.html</a></li></ol></section></article></main></div><div><footer id=site-footer class=toplevel-container><p>このサイトでは <a href=https://icons8.jp/>icons8</a> の素材を使用しています。</p><p>&copy; 2024 namoshika, All rights reserved</p></footer></div></div></body></html>